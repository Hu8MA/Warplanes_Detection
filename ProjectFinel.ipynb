{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMDGCrSI0FiAvnHCsw5UJI5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hu8MA/Warplanes_Detection/blob/main/ProjectFinel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "KJOwvCzMLpZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZQzGc-NT3pT"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2: we create new folder named(ProjectYolo7Final)"
      ],
      "metadata": {
        "id": "8wdh79jBBFvP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive"
      ],
      "metadata": {
        "id": "Vbp3LQRsBUu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if not os.path.isdir(\"ProjectYolo7Final\"):\n",
        "      os.makedirs(\"ProjectYolo7Final\")\n",
        ""
      ],
      "metadata": {
        "id": "9UtntYNKB0rH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3: access to folder \"ProjectYolo\""
      ],
      "metadata": {
        "id": "XqvlwYdQCpTn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ProjectYolo7Final"
      ],
      "metadata": {
        "id": "zLDCMfCNC163"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "Lr7AeLWOC64Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4: Downlod Yolov7 in this folder & weight"
      ],
      "metadata": {
        "id": "VFcRnq00C-O5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/WongKinYiu/yolov7.git\n",
        "%cd yolov7\n",
        "!pip install -r requirements.txt\n",
        "!wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7.pt"
      ],
      "metadata": {
        "id": "fn_9cJwuPIHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5: We modify the Yolo architecture through a number of steps:"
      ],
      "metadata": {
        "id": "-yxj6QNmKNse"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A- We are working on uploading the dataSet that we have created to the Google-Drive and it is inside the path drive/Mydrive/ProjectYolo/yolov7/data\n",
        "\n",
        "train file ,\n",
        "valid file ,\n",
        "test file\n"
      ],
      "metadata": {
        "id": "JQA4Q1kMLsYA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "B- Inside Yolo/data/  \n",
        "We are modifying the file COCO.yaml\n",
        "\n",
        "My image was 6018 image , The test rate was approved 15% (903 images), where 85% remains, of which 70% is for training (4347 images) and for verification 15%\n",
        "(768 images)\n",
        "to like this :\n",
        "\n",
        "train: ./data/train  # 4346 images\n",
        "val: ./data/val # 768 images\\n\n",
        "test: ./data/test # 903 of 40670 images\n",
        "\n",
        "number of classes\n",
        "nc: 5\n",
        "\n",
        "class names\n",
        "names: ['C130', 'F15', 'F16', 'F18', 'V22']"
      ],
      "metadata": {
        "id": "EP-32EWYL0_M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "C- Inside Yolo/cfg/training/yolov7\n",
        "\n",
        "*   List item = 5\n",
        ""
      ],
      "metadata": {
        "id": "bHHasQz_Mc_g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6: access to yolo7 directory"
      ],
      "metadata": {
        "id": "d8KeoRsiMzAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd yolov7"
      ],
      "metadata": {
        "id": "d7h9A2z-Nk8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "pjhZConmNvxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**7: Now , make training for this data set**"
      ],
      "metadata": {
        "id": "o0M6ooK1OfhN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we have tow weights **yolov7.pt** & **yolov7_training.pt**\n",
        "The algorithm builder insists on using yolov7_training.pt as the starting weight, but I've tried both, and they have almost the same effect."
      ],
      "metadata": {
        "id": "EhvUgOf5JL7j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Note\n",
        " this instruction was added (**--single-cls**), and it is one of the solutions that I was able to find after careful research and communication with engineers in this field, because there is a problem in the architecture when dealing with custom training data, where there is a problem in knowing the number of The entities that it will read from a file (coco) so we use this instruction to make it clear to the architecture that this data is from one entity (I know this is wrong, but our function in this project is Detection and tracking) so we do not need the classification function."
      ],
      "metadata": {
        "id": "GHdHWq-_O-jL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py  --single-cls --device 0 --weights yolov7.pt --data data/coco.yaml  --batch-size 16 --workers 8  --epochs 55 --img 640 640  --hyp data/hyp.scratch.custom.yaml --cfg  cfg/training/yolov7.yaml  --name yolov7-custom"
      ],
      "metadata": {
        "id": "SMdHXiMr1J84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --single-cls  --device 0  --single-cls --weights yolov7_training.pt --data data/coco.yaml  --batch-size 16 --workers 8  --epochs 20 --img 640 640  --hyp data/hyp.scratch.custom.yaml --cfg  cfg/training/yolov7.yaml  --name yolov77-custom"
      ],
      "metadata": {
        "id": "JPTJ-4eGFzDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#*8*:  A- Make Detectation for images"
      ],
      "metadata": {
        "id": "iYEoP0PvC2So"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4cfnLtTCIce"
      },
      "outputs": [],
      "source": [
        "!python detect.py --weights runs/train/yolov7-custom25/weights/best.pt --conf 0.25 --img-size 640  --source data/test/image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "0_itAIvctSZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# B- **detected** on vedio\n"
      ],
      "metadata": {
        "id": "Dd-_eLIMhj8I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "--weights \"your path\".pt\n",
        "...... normaly , is can found in runs/train/yolov7-custom/weights/best.pt"
      ],
      "metadata": {
        "id": "0I8nCKilPVQp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USbz7aKtfcly"
      },
      "outputs": [],
      "source": [
        "!python detect.py --weights \"your path\".pt --conf 0.25 --img-size 640  --source \"your path\".mp4"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#9: Display images"
      ],
      "metadata": {
        "id": "khu-5vKlD0b4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6AGhNOSSHY4_"
      },
      "outputs": [],
      "source": [
        "\n",
        "import glob\n",
        "from IPython.display import Image, display\n",
        "\n",
        "i = 0\n",
        "limit = 10000 # max images to print\n",
        "for imageName in glob.glob('your path of one image .jpg'): #assuming JPG\n",
        "    if i < limit:\n",
        "      display(Image(filename=imageName))\n",
        "      print(\"\\n\")\n",
        "    i = i + 1\n",
        "\n",
        "#if you have many images so can use\n",
        "#glob.glob('your path of folder/* .jpg'):\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Note**\n",
        "If you have a video and want to test it, you must ensure that each of its frames is in the size of 640 * 640\n",
        "So this code works to reset the frame size in the video so that the output is a video, all of its frames are 640 * 640"
      ],
      "metadata": {
        "id": "IooDZ85IKWGK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "# Open the video file\n",
        "video = cv2.VideoCapture('your path')\n",
        "\n",
        "# Get the dimensions of the original video frame\n",
        "width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "# Define the new dimensions for the resized frame\n",
        "new_width = 640\n",
        "new_height = 640\n",
        "\n",
        "# Define the codec and create a VideoWriter object\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # for mp4 format\n",
        "out = cv2.VideoWriter('your path to save file', fourcc, 30, (new_width, new_height))\n",
        "\n",
        "# Loop through the video frames\n",
        "while True:\n",
        "    # Read a frame from the video\n",
        "    ret, frame = video.read()\n",
        "\n",
        "    # Check if we have reached the end of the video\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Resize the frame\n",
        "    resized_frame = cv2.resize(frame, (new_width, new_height))\n",
        "\n",
        "    # Write the resized frame to the output video file\n",
        "    out.write(resized_frame)\n",
        "\n",
        "    # Display the resized frame\n",
        "    print('Resized Frame', resized_frame)\n",
        "\n",
        "    # Check for keyboard input to exit the loop\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release the video objects and close the window\n",
        "video.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "H9vh2NVzz8eu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}